# AI-Powered Virtual Trainer for Presentation Skills Web Application

## Introduction

**Speakraft** is an innovative platform designed to help users master their presentation skills and build confidence. The platform focuses on enhancing voice modulation, facial expressions, and hand gestures. Key features include tools for time management, overcoming mid-presentation pauses, reducing filler words, improving pronunciation, pitch, and tone, as well as refining content. **Speakraft** also offers personalized tools to improve facial and hand movements, along with a detailed post-analysis and overall performance score to help users track and improve their progress effectively.

## Architecture Diagram
![Architecture Diagram](https://github.com/user-attachments/assets/2a90c322-04e7-443d-a17d-51bd64d37cab)


## Project & Repositories

- [Project](https://github.com/Speak-Craft)
- [Model Repository](https://github.com/Speak-Craft/modal)
- [Backend Repository](https://github.com/Speak-Craft/backend)
- [Frontend Repository](https://github.com/Speak-Craft/frontend)

---

## Supervisor

- **Supervisor**: [Dr. Samantha Rajapaksha](https://www.linkedin.com/in/samantha-rajapaksha-528657b/)
- **Co-Supervisor**: [Mr. Samadhi Rathnayake](https://www.linkedin.com/in/samadhi-chathuranga-rathnayake/)

## Team Members

| Member           | IT Number  | Sub-Objective                                        | Tasks                                                                             |
| ---------------- | ---------- | ---------------------------------------------------- | --------------------------------------------------------------------------------- |
| [Madhushan W.C.P]()  | IT21810732 | Filler Words and Time Management                     | Detects and highlights the usage of filler words during the presentation.         |
| Boralugoda D.S   | IT21279348 | Pitch and Tone Modulation Analysis                   | Analyze variations in pitch and tone throughout the speech.                       |
| [Vishara D.D.S](https://github.com/VISHARADDS)    | IT21822544 | Object and Environment Identification                | Tracks the user’s speaking rate , pauses and breathing, pacing curve.             |
| [Perera M.P.A.M]()   | IT21808784 | Pace Management                                      | Analyze facial expressions during presentations.                                  |

## Features

## 1.Facial Expression Analysis:
- Activities: Evaluates expressions like smiling, frowning, or neutral demeanorduring presentations.
- Feedback: Suggests improvements such as “Increase eye contact” or “Smile during key moments” to promote engagement.

## 2.Pitch and Tone Modulation Analysis:
- Activities: Analyzes vocal pitch and tone to identify monotony or unclear delivery.
- Feedback: Highlights areas needing more variation and suggests tonal improvements for effective delivery.

## 3.Filler Words and Time Management:
- Activities: Tracks the user’s speaking rate and provides insights to manage pacing effectively.
- Feedback: Alerts users about slow or fast delivery and provides strategies for balanced pacing.

## 4.Pace Management:
- Activities: Tracks the user’s speaking rate, pauses and breathing and provides insights to manage pacing effectively.
- Feedback: Alerts users about slow or fast delivery and provides strategies for balanced pacing.


## Objectives

### Main Objective

The primary objective of the AI-Powered Virtual Trainer for Presentation Skills is to provide an intelligent, immersive, and personalized platform that enhances both verbal and non - verbal communication skills. By leveraging AI and advanced technologies. The ultimate goal is to empower users with the tools and insights needed to become compelling speakers who can effectively captivate and influence their audiences.

### Sub-Objectives

- **Madhushan W.C.P**: Develop a gamification part for filler word and Time management.
- **Boralugoda D.S.**: To enable presenters to effectively use pitch and tone modulation, ensuring their delivery is engaging, emotionally resonant, and aligned with the content of their presentation..
- **Vishara D.D.S.**: Develop a gamification part for Pace Management.
- **Perera M.P.A.M.**: Ensures that facial expressions effectively and complement the content.

---

## Technology Stack

### Programming Languages

- **Frontend**: React.js
- **Backend**: Java
- **Machine Learning**: Python
- **Database**: PostgreSQL

### Frameworks

- **Frontend**: React.js, Vite, Ant Design
- **Backend**: Spring Boot

### Machine Learning Frameworks

- TensorFlow.js
- OpenCV.js
- Keras
- Wispher
- Mccs

### Tools

- Figma
- Postman
- GitHub
- SonarQube
- Java CI with Maven

---

## References

## 1. Anderson, C., & Anderson, T. (2016). TED Talks: The Official TED Guide to Public Speaking. Houghton Mifflin Harcourt.
a. Discusses the importance of clear communication and techniques for effective presentations.

## 2. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.
a. Provides foundational concepts in machine learning relevant to speech and facial expression analysis.

## 3. Boersma, P., & Weenink, D. (2001). Praat: Doing Phonetics by Computer. [Online].
Available at: https://www.fon.hum.uva.nl/praat/
a. A tool for analyzing and manipulating speech used in pitch and tone analysis.

## 4. Chollet, F. (2017). Deep Learning with Python. Manning Publications.
a. Covers deep learning techniques applicable to facial expression recognition and NLP.

## 5. Kapoor, S., & Picard, R. W. (2005). Multimodal affect recognition in learning environments. Proceedings of the 13th Annual ACM International Conference on Multimedia, 677-682.
a. Explores the integration of affective computing and multimodal analysis in user training.

## 6. McNeill, D. (2005). Gesture and thought. University of Chicago Press.
a. Provides insights into the importance of non-verbal communication, relevant for analyzing filler words and body language.

## 7. Microsoft Azure. (2023). Kinect SDK Documentation. [Online]. Available at: https://learn.microsoft.com/en-us/azure/kinect-dk/
a. Documentation for body tracking and gesture recognition tools applicable to real-time feedback systems.

## 8. Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). Attention is all you need. Advances in Neural Information Processing Systems, 30.
a. Introduces transformer models, which are critical for NLP tasks like filler word detection and speech analysis.
